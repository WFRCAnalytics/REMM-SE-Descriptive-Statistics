{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from arcpy import env\n",
    "import os\n",
    "import numpy as np\n",
    "from arcgis import GIS\n",
    "from arcgis.features import GeoAccessor\n",
    "from arcgis.features import GeoSeriesAccessor\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.parallelProcessingFactor = \"90%\"\n",
    "\n",
    "# show all columns\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# pd.DataFrame.spatial.from_featureclass(???)  \n",
    "# df.spatial.to_featureclass(location=???,sanitize_columns=False)  \n",
    "\n",
    "# gsa = arcgis.features.GeoSeriesAccessor(df['SHAPE'])  \n",
    "# df['AREA'] = gsa.area  # KNOW YOUR UNITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NA values in Spatially enabled dataframes (ignores SHAPE column)\n",
    "def fill_na_sedf(df_with_shape_column, fill_value=0):\n",
    "    if 'SHAPE' in list(df_with_shape_column.columns):\n",
    "        df = df_with_shape_column.copy()\n",
    "        shape_column = df['SHAPE'].copy()\n",
    "        del df['SHAPE']\n",
    "        return df.fillna(fill_value).merge(shape_column,left_index=True, right_index=True, how='inner')\n",
    "    else:\n",
    "        raise Exception(\"Dataframe does not include 'SHAPE' column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_year = 2019\n",
    "# base_year = 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "if base_year == 2015:\n",
    "    outputs = r'.\\\\Outputs\\progession_metrics_average_2015'\n",
    "if base_year == 2019:\n",
    "    outputs = r'.\\\\Outputs\\progession_metrics_average'\n",
    "\n",
    "if not os.path.exists(outputs):\n",
    "    os.makedirs(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parcel Equivalency Table\n",
    "# if base_year == 2015:\n",
    "#     eq = pd.read_csv(r\".\\Inputs\\parcel_eq_2015_v1.csv\")\n",
    "# if base_year == 2019:\n",
    "#     eq = pd.read_csv(r\".\\Inputs\\parcel_eq_v5.csv\")\n",
    "    \n",
    "# centers_eq_ids = eq[eq['CENTER_NAME'].isna() == False]['parcel_id'].to_list()\n",
    "\n",
    "# # centers shape\n",
    "# centers_sdf = pd.DataFrame.spatial.from_featureclass(r\".\\Inputs\\WC_2050_Centers.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "if base_year == 2015:\n",
    "    remm_folder_1 = r\"\\\\server1\\Volumef\\SHARED\\Josh\\REMM Runs\\Progression_Metrics_2015_1\"\n",
    "    remm_folder_2 = r\"\\\\server1\\Volumef\\SHARED\\Josh\\REMM Runs\\Progression_Metrics_2015_2\"\n",
    "    remm_folder_3 = r\"\\\\server1\\Volumef\\SHARED\\Josh\\REMM Runs\\Progression_Metrics_2015_3\"\n",
    "    remm_folder_4 = r\"\\\\server1\\Volumef\\SHARED\\Josh\\REMM Runs\\Progression_Metrics_2015_4\"\n",
    "    remm_folder_5 = r\"\\\\server1\\Volumef\\SHARED\\Josh\\REMM Runs\\Progression_Metrics_2015_5\"\n",
    "    remm_folder_6 = r\"\\\\server1\\Volumef\\SHARED\\Josh\\REMM Runs\\Progression_Metrics_2015_6\"\n",
    "\n",
    "if base_year == 2019:\n",
    "    remm_folder_1 = r\"E:\\Projects\\REMM2_For_Python3_Internal_Use_1\\REMMRun\\Progression_Metrics\"\n",
    "    remm_folder_2 = r\"E:\\Projects\\REMM2_For_Python3_Internal_Use_2\\REMMRun\\Progression_Metrics\"\n",
    "    remm_folder_3 = r\"E:\\Projects\\REMM2_For_Python3_Internal_Use_3\\REMMRun\\Progression_Metrics\"\n",
    "    remm_folder_4 = r\"\\\\modelqueen\\ModelQueen-D\\Josh_Projects\\REMM2_For_Python3_Internal_Use_1\\REMMRun\\Progression_Metrics\"\n",
    "    remm_folder_5 = r\"\\\\modelqueen\\ModelQueen-D\\Josh_Projects\\REMM2_For_Python3_Internal_Use_2\\REMMRun\\Progression_Metrics\"\n",
    "    remm_folder_6 = r\"\\\\modelqueen\\ModelQueen-D\\Josh_Projects\\REMM2_For_Python3_Internal_Use_3\\REMMRun\\Progression_Metrics\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "remm_progression_folders = [remm_folder_1, remm_folder_2, remm_folder_3, remm_folder_4, remm_folder_5, remm_folder_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # csv version\n",
    "# def get_table_ignore_base(path, year):\n",
    "#     csvs = glob.glob(os.path.join(path, f'run_*_year_{year}_parcel_progression_metrics.csv'))\n",
    "#     csvs = [csv for csv in csvs if 'base'not in csv]\n",
    "#     if len(csvs) > 1:\n",
    "#         print('warning multiple tables were globbed; only the first will be returned')\n",
    "#     return pd.read_csv(csvs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkl version\n",
    "def get_table_ignore_base(path, year):\n",
    "    pkls = glob.glob(os.path.join(path, f'run_*_year_{year}_parcel_progression_metrics.pkl'))\n",
    "    pkls = [pkl for pkl in pkls if 'base'not in pkl]\n",
    "    if len(pkls) > 1:\n",
    "        print('warning multiple tables were globbed; only the first will be returned')\n",
    "    return pd.read_pickle(pkls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(df, year):\n",
    "    df = df.set_index('parcel_id')\n",
    "    df.loc[(df['is_sf']==1), 'sf_units'] = df['residential_units']\n",
    "    df.loc[(df['is_mf']==1), 'mf_units'] = df['residential_units']\n",
    "    df['industrial_jobs'] = df['jobs_wholesale'] + df['jobs_manuf']\n",
    "    df['retail_jobs'] = df['jobs_retail'] + df['jobs_accom_food']\n",
    "    df['office_jobs'] = df['jobs_office'] + df['jobs_gov_edu'] + df['jobs_health'] + df['jobs_other']\n",
    "    df.loc[(df['has_buildings'] != 1), 'vacant_acres'] = df['parcel_acres']\n",
    "    df.loc[(df['has_buildings'] != 1) & (df['developable'] == 1), 'vacant_devacres'] = df['parcel_acres']\n",
    "    df['vacant_acres'].fillna(0, inplace=True)\n",
    "    df['vacant_devacres'].fillna(0, inplace=True)\n",
    "    df['households'] = df['households_count']\n",
    "    df = df[['sf_units', 'mf_units', 'households', 'hhpop', 'job_spaces', 'industrial_jobs', 'retail_jobs', 'office_jobs', 'vacant_acres', 'vacant_devacres']].copy()\n",
    "    return df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base = centers_sdf[['CenterName', 'DEVACRES', 'SHAPE']].copy()\n",
    "for year in range(base_year,2051):\n",
    "    dfs_current_year = [get_table_ignore_base(f, year) for f in remm_progression_folders]\n",
    "    dfs_processed = [prepare_df(df, year) for df in dfs_current_year] \n",
    "\n",
    "    # stack average the 6 runs together\n",
    "    data_stack = pd.concat(dfs_processed)\n",
    "    average = data_stack.groupby(data_stack.index).mean().reset_index().round().astype(int)\n",
    "    average['residential_units'] = average['sf_units'] + average['mf_units']\n",
    "    average['total_jobs'] = average['office_jobs'] + average['retail_jobs'] + average['industrial_jobs']\n",
    "\n",
    "    if base_year == 2015:\n",
    "        average.to_pickle(os.path.join(outputs, f'averaged_parcel_se_b2015_{year}.pkl'))\n",
    "    if base_year == 2019:\n",
    "        average.to_pickle(os.path.join(outputs, f'averaged_parcel_se_{year}.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test\n",
    "# unpickled_df = pd.read_pickle(r\"\\\\server1\\Volumef\\SHARED\\Josh\\REMM Runs\\Progression_Metrics_2015_1\\run_362_year_2015_parcel_progression_metrics.pkl\")\n",
    "# unpickled_df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3245673af07dcc28bdd829afb187282e9288a1f8195a5928b70ecba6e5973721"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
